import os
from openai import OpenAI
from typing import List, Dict, Any

# Tenta a importa√ß√£o relativa primeiro (para uvicorn)
try:
    from .ml_engine import ml_engine, ScreenAnalysis
except ImportError:
    from ml_engine import ml_engine, ScreenAnalysis

# Inicializa o cliente OpenAI
# As vari√°veis de ambiente OPENAI_API_KEY e BASE_URL s√£o configuradas automaticamente
try:
    client = OpenAI()
except Exception as e:
    print(f"‚ö†Ô∏è Erro ao inicializar o cliente OpenAI: {e}")
    client = None

# Modelo a ser utilizado
MODEL_NAME = os.environ.get("LLM_MODEL", "gpt-4.1-mini")

# ============================================
# FUN√á√ïES DE GERA√á√ÉO DE CEN√ÅRIO GHERKIN
# ============================================

def generate_gherkin_scenario(
    screen_analysis: ScreenAnalysis, 
    user_intent: str, 
    conversation_history: List[Dict[str, str]]
) -> str:
    """
    Gera um cen√°rio Gherkin completo usando um LLM ou o motor de ML,
    baseado na an√°lise de tela, inten√ß√£o do usu√°rio e hist√≥rico da conversa.
    """
    
    # Se o cliente LLM n√£o est√° dispon√≠vel, usar o motor de ML
    if not client:
        return ml_engine.generate_gherkin(screen_analysis, user_intent)

    # 1. Construir o hist√≥rico de mensagens para o LLM
    messages = [
        {"role": "system", "content": f"""Voc√™ √© o NEBULA AGENT 6.0, um especialista em BDD (Behavior-Driven Development) e automa√ß√£o de testes.
Sua √∫nica fun√ß√£o √© analisar o contexto fornecido (an√°lise de tela, elementos identificados e hist√≥rico da conversa) 
e gerar um **CEN√ÅRIO GHERKIN** completo e otimizado para o teste de software.

O Gherkin deve ser focado na **inten√ß√£o do usu√°rio** e na **funcionalidade principal** da tela.
A sa√≠da DEVE ser formatada em um bloco de c√≥digo Markdown Gherkin, come√ßando com a tag `Feature:`.

**Instru√ß√µes:**
1.  **Feature:** Deve ser um t√≠tulo conciso sobre a funcionalidade principal.
2.  **Scenario:** Deve descrever o caso de uso principal.
3.  **Given:** O contexto inicial (ex: "Dado que o usu√°rio est√° na tela de login").
4.  **When:** A a√ß√£o do usu√°rio (ex: "Quando ele preenche os campos 'Usu√°rio' e 'Senha'").
5.  **Then:** O resultado esperado (ex: "Ent√£o ele deve ser redirecionado para a p√°gina inicial").

**Contexto da An√°lise:**
- **Tipo de Tela:** {screen_analysis.screen_type.value}
- **Confian√ßa:** {screen_analysis.confidence:.0%}
- **Elementos:** {', '.join([elem.label for elem in screen_analysis.elements])}
- **Inten√ß√£o do Usu√°rio:** {user_intent}
"""}
    ]

    # Adicionar o hist√≥rico da conversa (limitando para evitar tokens excessivos)
    for item in conversation_history[-5:]:
        role = "user" if item["role"] == "user" else "assistant"
        messages.append({"role": role, "content": item["content"]})

    # Adicionar a √∫ltima inten√ß√£o do usu√°rio como a mensagem final
    messages.append({"role": "user", "content": f"Minha inten√ß√£o √©: {user_intent}. Gere o cen√°rio Gherkin."})

    try:
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=messages,
            temperature=0.2,
            max_tokens=1024
        )
        
        # Extrair e limpar o texto gerado
        gherkin_text = response.choices[0].message.content.strip()
        
        # Tentar extrair apenas o bloco de c√≥digo Gherkin
        if "```gherkin" in gherkin_text:
            start = gherkin_text.find("```gherkin") + len("```gherkin")
            end = gherkin_text.find("```", start)
            return gherkin_text[start:end].strip()
        elif "```" in gherkin_text:
            start = gherkin_text.find("```") + len("```")
            end = gherkin_text.find("```", start)
            return gherkin_text[start:end].strip()
        
        return gherkin_text

    except Exception as e:
        print(f"‚ùå Erro na chamada do LLM: {e}")
        # Fallback para o motor de ML
        return ml_engine.generate_gherkin(screen_analysis, user_intent)


# ============================================
# FUN√á√ÉO DE AN√ÅLISE DE TELA
# ============================================

def simulate_screen_analysis(message: str) -> ScreenAnalysis:
    """
    Simula a an√°lise visual de uma tela usando o motor de ML.
    Retorna um objeto ScreenAnalysis com informa√ß√µes detalhadas.
    """
    msg_lower = message.lower()
    
    # Mapear inten√ß√£o do usu√°rio para descri√ß√£o de tela
    screen_descriptions = {
        "login": "Tela de Login com campos 'Usu√°rio', 'Senha', bot√£o 'Entrar' e link 'Esqueci a Senha'.",
        "logar": "Tela de Login com campos 'Usu√°rio', 'Senha', bot√£o 'Entrar' e link 'Esqueci a Senha'.",
        "cadastro": "Tela de Cadastro de Novo Usu√°rio com campos 'Nome', 'Email', 'CPF', 'Senha', 'Confirmar Senha' e bot√£o 'Criar Conta'.",
        "registrar": "Tela de Cadastro de Novo Usu√°rio com campos 'Nome', 'Email', 'CPF', 'Senha', 'Confirmar Senha' e bot√£o 'Criar Conta'.",
        "checkout": "Tela de Checkout com formul√°rio de endere√ßo, sele√ß√£o de m√©todo de pagamento (Cart√£o, Pix) e bot√£o 'Finalizar Compra'.",
        "pagamento": "Tela de Checkout com formul√°rio de endere√ßo, sele√ß√£o de m√©todo de pagamento (Cart√£o, Pix) e bot√£o 'Finalizar Compra'.",
    }
    
    # Encontrar a descri√ß√£o mais apropriada
    screen_desc = "Tela Gen√©rica com formul√°rio e bot√£o de a√ß√£o."
    for keyword, desc in screen_descriptions.items():
        if keyword in msg_lower:
            screen_desc = desc
            break
    
    # Usar o motor de ML para analisar a tela
    return ml_engine.analyze_screen(screen_desc)


# ============================================
# FUN√á√ÉO DE AGENTE (PROCESSAMENTO PRINCIPAL)
# ============================================

def process_as_agent(message: str, state: Dict[str, Any]) -> str:
    """
    Fun√ß√£o principal do agente que decide a a√ß√£o a ser tomada.
    Integra an√°lise de tela com ML e gera√ß√£o de Gherkin.
    """
    
    msg_lower = message.lower()
    
    # Se o usu√°rio pedir para gerar Gherkin, cen√°rio ou teste
    if any(keyword in msg_lower for keyword in ["gherkin", "cen√°rio", "teste", "automatizar", "validar"]):
        
        # 1. Analisar a tela usando o motor de ML
        screen_analysis = simulate_screen_analysis(message)
        
        # 2. Gerar o cen√°rio Gherkin
        gherkin = generate_gherkin_scenario(screen_analysis, message, state["conversation_history"])
        
        # 3. Montar a resposta com informa√ß√µes detalhadas
        response = f"""‚úÖ **Cen√°rio Gherkin Gerado com Sucesso!**

**An√°lise da Tela:**
- Tipo: {screen_analysis.screen_type.value}
- Confian√ßa: {screen_analysis.confidence:.0%}
- Elementos Identificados: {len(screen_analysis.elements)}

**Cen√°rio Gherkin:**
```gherkin
{gherkin}
```

**Pr√≥ximos Passos:**
1. Executar o teste automatizado
2. Validar os resultados
3. Corrigir falhas se necess√°rio
4. Atualizar o cen√°rio conforme necess√°rio"""
        
        return response
    
    # Se o usu√°rio pedir para analisar uma tela
    elif any(keyword in msg_lower for keyword in ["analisar", "an√°lise", "tela", "screen"]):
        
        screen_analysis = simulate_screen_analysis(message)
        
        elements_str = "\n".join([f"- {elem.label} ({elem.element_type.value})" for elem in screen_analysis.elements])
        
        response = f"""üìä **An√°lise da Tela Conclu√≠da**

**Tipo de Tela:** {screen_analysis.screen_type.value}
**Confian√ßa:** {screen_analysis.confidence:.0%}

**Elementos Identificados:**
{elements_str}

**Palavras-chave:** {', '.join(screen_analysis.keywords)}

Deseja que eu gere um cen√°rio Gherkin para esta tela?"""
        
        return response

    # Resposta padr√£o
    return f"""ü§ñ **Entendido!** Sua solicita√ß√£o foi: '{message}'.

Sou especializada em:
- üìù **Gerar cen√°rios Gherkin** para testes automatizados
- üîç **Analisar telas** e identificar elementos
- ü§ñ **Automatizar testes** de aplica√ß√µes
- üìä **Validar funcionalidades** com BDD

Tente me pedir para:
- "Gerar um cen√°rio Gherkin para uma tela de login"
- "Analisar a tela de checkout"
- "Criar um teste para validar o cadastro\""""


# ============================================
# FUN√á√ÉO DE SA√öDE
# ============================================

def is_llm_available() -> bool:
    """Verifica se o cliente LLM est√° pronto para uso."""
    return client is not None


if __name__ == "__main__":
    # Exemplo de uso (apenas para teste local)
    print("--- Teste de Gera√ß√£o Gherkin ---")
    mock_state = {"conversation_history": []}
    mock_message = "Gerar um cen√°rio Gherkin para o fluxo de login com sucesso"
    
    result = process_as_agent(mock_message, mock_state)
    print(result)

